{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before you start  \n",
    "Make sure you run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "from slugify import slugify\n",
    "from glob import glob\n",
    "from utils.parse_terrier_output import parse_stats, parse_run_results, parse_evaluation_results\n",
    "from utils.read_eval import read_eval, get_recalls\n",
    "from utils.logging import write_log\n",
    "\n",
    "terrier_path = r\"/Users/fferegrino/Documents/terrier-core-4.2\"\n",
    "\n",
    "logs_folder = r\"/Users/fferegrino/Documents/GitHub/ir-ae1/logs\"\n",
    "results_folder = r\"/Users/fferegrino/Documents/terrier-core-4.2/var/results\"\n",
    "\n",
    "dataframes_path= \"results\"\n",
    "\n",
    "sh_or_bat = \"sh\"\n",
    "if os.name == 'nt':\n",
    "    sh_or_bat = \"bat\"\n",
    "    \n",
    "setup = join(terrier_path, \"bin\", \"trec_setup.%s\" % sh_or_bat)\n",
    "terrier = join(terrier_path, \"bin\", \"trec_terrier.%s\" % sh_or_bat)\n",
    "teval = join(terrier_path, \"bin\", \"trec_eval.%s\" % sh_or_bat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup topics:  \n",
    "\n",
    "(This is for the assessed exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp = ['HP04', 'NP04', 'TD04']\n",
    "models = ['LnTfIdfModel', 'Log10TfIdfModel', 'LogTfIdfModel', 'TF_IDF' , 'BM25', 'PL2']\n",
    "query_exp = ['','-q']\n",
    "combinations = [comb for comb in itertools.product(tp, models,query_exp)]\n",
    "java_models = {\n",
    "    'LnTfIdfModel': 'com.thatcsharpguy.models.LnTfIdfModel',\n",
    "    'Log10TfIdfModel': 'com.thatcsharpguy.models.Log10TfIdfModel',\n",
    "    'LogTfIdfModel': 'com.thatcsharpguy.models.LogTfIdfModel'\n",
    "}\n",
    "classpath = r\"/Users/fferegrino/Documents/GitHub/ir-ae1/custom-model/target/ircourse-1.0-SNAPSHOT.jar\"\n",
    "\n",
    "topics = {}\n",
    "qrels = {}\n",
    "for topic in tp:\n",
    "    topics[topic] = r\"/Users/fferegrino/Documents/ae1/TopicsQrels/%s/topics\" % topic\n",
    "    qrels[topic] = r\"/Users/fferegrino/Documents/ae1/TopicsQrels/%s/qrels\" % topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1;34mINFO\u001b[m] Scanning for projects...\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1mBuilding ircourse 1.0-SNAPSHOT\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-clean-plugin:2.5:clean\u001b[m \u001b[1m(default-clean)\u001b[m @ \u001b[36mircourse\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1;32mBUILD SUCCESS\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Total time: 0.511 s\n",
      "[\u001b[1;34mINFO\u001b[m] Finished at: 2018-02-01T22:57:13Z\n",
      "[\u001b[1;34mINFO\u001b[m] Final Memory: 7M/123M\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Scanning for projects...\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1mBuilding ircourse 1.0-SNAPSHOT\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-resources-plugin:2.6:resources\u001b[m \u001b[1m(default-resources)\u001b[m @ \u001b[36mircourse\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;33mWARNING\u001b[m] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!\n",
      "[\u001b[1;34mINFO\u001b[m] skip non existing resourceDirectory /Users/fferegrino/Documents/GitHub/ir-ae1/nb/../custom-model/src/main/resources\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-compiler-plugin:2.3.2:compile\u001b[m \u001b[1m(default-compile)\u001b[m @ \u001b[36mircourse\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;33mWARNING\u001b[m] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!\n",
      "[\u001b[1;34mINFO\u001b[m] Compiling 4 source files to /Users/fferegrino/Documents/GitHub/ir-ae1/nb/../custom-model/target/classes\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-resources-plugin:2.6:testResources\u001b[m \u001b[1m(default-testResources)\u001b[m @ \u001b[36mircourse\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;33mWARNING\u001b[m] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent!\n",
      "[\u001b[1;34mINFO\u001b[m] skip non existing resourceDirectory /Users/fferegrino/Documents/GitHub/ir-ae1/nb/../custom-model/src/test/resources\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-compiler-plugin:2.3.2:testCompile\u001b[m \u001b[1m(default-testCompile)\u001b[m @ \u001b[36mircourse\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;33mWARNING\u001b[m] File encoding has not been set, using platform encoding UTF-8, i.e. build is platform dependent!\n",
      "[\u001b[1;34mINFO\u001b[m] Compiling 1 source file to /Users/fferegrino/Documents/GitHub/ir-ae1/nb/../custom-model/target/test-classes\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-surefire-plugin:2.12.4:test\u001b[m \u001b[1m(default-test)\u001b[m @ \u001b[36mircourse\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m--- \u001b[0;32mmaven-jar-plugin:2.4:jar\u001b[m \u001b[1m(default-jar)\u001b[m @ \u001b[36mircourse\u001b[0;1m ---\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Building jar: /Users/fferegrino/Documents/GitHub/ir-ae1/nb/../custom-model/target/ircourse-1.0-SNAPSHOT.jar\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1;32mBUILD SUCCESS\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n",
      "[\u001b[1;34mINFO\u001b[m] Total time: 3.366 s\n",
      "[\u001b[1;34mINFO\u001b[m] Finished at: 2018-02-01T22:57:17Z\n",
      "[\u001b[1;34mINFO\u001b[m] Final Memory: 41M/306M\n",
      "[\u001b[1;34mINFO\u001b[m] \u001b[1m------------------------------------------------------------------------\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# Compile models  \n",
    "!mvn clean -f ../custom-model/\n",
    "!mvn package -f ../custom-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# http://terrier.org/docs/v4.2/configure_retrieval.html\n",
    "\n",
    "for comb in combinations:\n",
    "    topic = comb[0]\n",
    "    model = comb[1]\n",
    "    qexp = comb[2]\n",
    "    topics_file = topics[topic]\n",
    "    results_file = join(results_folder,  topic + \"-\" + model + qexp + \".res\")\n",
    "    \n",
    "    model_name = java_models.get(model, model)\n",
    "    \n",
    "    command=\"CLASSPATH=%s %s -r %s -Dtrec.topics=%s -Dtrec.results.file=%s -Dtrec.model=%s\" % (classpath,\n",
    "                                                                                            terrier, \n",
    "                                                                                               qexp,\n",
    "                                                                                            topics_file, \n",
    "                                                                                            results_file,\n",
    "                                                                                            model_name)\n",
    "    run_results = !$command\n",
    "    write_log(join(logs_folder,\"run-%s-%s%s.txt\" % (topic, model, qexp)), run_results, command)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://terrier.org/docs/v4.2/evaluation.html\n",
    "for comb in combinations:\n",
    "    topic = comb[0]\n",
    "    model = comb[1]\n",
    "    qexp = comb[2]\n",
    "    qrels_file = qrels[topic]\n",
    "    results_file = join(results_folder,  topic + \"-\" + model  + qexp + \".res\")\n",
    "    eval_file = join(results_folder,  topic + \"-\" + model + qexp  + \".eval\")\n",
    "    command = \"%s %s %s -q > %s\" % (teval, qrels_file, results_file, eval_file)\n",
    "    evaluation_results = !$command\n",
    "    write_log(join(logs_folder,\"eval-%s-%s%s.txt\" % (topic, model,qexp)), evaluation_results, command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_eval(eval_file, skip_first=True):\n",
    "    data = pd.read_table(eval_file,\n",
    "                         sep='\\t',\n",
    "                         header=None,\n",
    "                         skiprows=[0] if skip_first else None,\n",
    "                         names=['measure', 'query', 'value'])\n",
    "    # Split frames:\n",
    "    data.dropna(inplace=True)\n",
    "    data['measure'] = data['measure'].str.strip()\n",
    "    \n",
    "    per_query = data[data['query'] != 'all'].pivot(index='query', columns='measure', values='value')\n",
    "    per_query.index = per_query.index.astype(int)\n",
    "    per_query.sort_index(inplace=True)\n",
    "    \n",
    "    totals = data[data['query'] == 'all'].pivot(index='query', columns='measure', values='value')\n",
    "    \n",
    "    return totals, per_query\n",
    "\n",
    "dataframes = {}\n",
    "for comb in combinations:\n",
    "    topic = comb[0]\n",
    "    model = comb[1]\n",
    "    qexp = comb[2]\n",
    "    ev_file = join(results_folder,  topic + \"-\" + model + qexp + \".eval\")\n",
    "    total, per_query = read_eval(ev_file,True)\n",
    "    if total is None or len(total) == 0:\n",
    "        print(comb,\"has no total\")\n",
    "    if per_query is None or len(per_query) == 0:\n",
    "        print(comb,\"has no per query\")\n",
    "        \n",
    "    total.to_csv(os.path.join(dataframes_path, \"total_%s_%s%s.csv\" %(topic, model, qexp)))\n",
    "    per_query.to_csv(os.path.join(dataframes_path, \"per_query_%s_%s%s.csv\" %(topic, model, qexp)))\n",
    "    dataframes[ topic + \"_\" + model] = {\n",
    "        'total': total,\n",
    "        'per_query': per_query\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
